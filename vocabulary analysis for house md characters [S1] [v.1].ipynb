{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The transcript was obtained from clinic-duty.livejournal.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUMMARY\n",
    "\n",
    "##### About House\n",
    "* House had the most vocabularies compared to the others. Obviously, since he's the main character.  \n",
    "* House said 69 lie/lies/lied/lying words. Quite enough. Considering \"Everybody lies\" jargon was being campaigned through this season. But the minus is 'lie' as in lie down could be mixed in there.  \n",
    "\n",
    "##### Commentary on characters' nouns/adjectives/verbs\n",
    "* I'm a bit dissapointed that the differences between everyone's noun/adj/verb are not that noticeable. Oh except Cuddy's nouns. That's so her lol.  \n",
    "* \"cancer\" spotted on Wilson's nouns. Score! And \"die\" lol (must be talking about his patients)  \n",
    "* Uh, apparently, Wilson said \"uh\" the most among the characters.  \n",
    "* Chase said \"poison\" 12 times. Did he jump onto poisoning on DDX too much in this season? I forgot    \n",
    "* Cameron said \"history\" 11 times. Ptient history I guess. She cared about them the most, huh?  \n",
    "* \"brain\" for our neurologist Foreman. Point for me. And he said \"treatment\" the most.  \n",
    "* \"need\" appeared on Wilson's and Cameron's top verbs. Both were bleeding-heart-character. Is there any correlation?\n",
    "\n",
    "##### What to improve later\n",
    "* make a visualization\n",
    "* seek a way to distinguish 'unique' noun/adj/verb for the characters (odd ratio?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [House's Vocabularies in S1]\n",
    "\n",
    "##### House's unique vocabularies:\n",
    "4258  \n",
    "\n",
    "##### How many times House said lie/lies/lied\n",
    "69  \n",
    "\n",
    "##### House's top 10 nouns:\n",
    "get : 99,\n",
    "time : 91, \n",
    "guy : 81,\n",
    "people : 74, \n",
    "way : 70,\n",
    "something : 69,\n",
    "yeah : 65,\n",
    "doctor : 65,\n",
    "blood : 58,\n",
    "thing : 55\n",
    "\n",
    "##### House's top 10 adjectives:\n",
    "good : 98,\n",
    "right : 83,\n",
    "sure : 62,\n",
    "wrong : 60,\n",
    "new : 46,\n",
    "bad : 46,\n",
    "big : 44,\n",
    "little : 44,\n",
    "much : 40,\n",
    "great : 38\n",
    "\n",
    "##### House's top 10 verbs:\n",
    "get : 316,\n",
    "go : 195,\n",
    "know : 190,\n",
    "think : 157,\n",
    "would : 145,\n",
    "say : 136,\n",
    "want : 127,\n",
    "make : 123,\n",
    "could : 94,\n",
    "take : 86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Cuddy's Vocabularies in S1]\n",
    "\n",
    "##### Cuddy's unique vocabularies:\n",
    "1062 \n",
    "\n",
    "##### Cuddy's top 10 nouns:\n",
    "house : 22,\n",
    "dr : 17,\n",
    "doctor : 16,\n",
    "people : 13,\n",
    "hospital : 11,\n",
    "guy : 10,\n",
    "job : 10,\n",
    "week : 10,\n",
    "work : 9,\n",
    "talk : 9\n",
    "\n",
    "##### Cuddy's top 10 adjectives:\n",
    "good : 10,\n",
    "right : 8,\n",
    "clinic : 7,\n",
    "patient : 7,\n",
    "give : 7,\n",
    "wrong : 7,\n",
    "dr : 6,\n",
    "sure : 5,\n",
    "fine : 4,\n",
    "great : 4\n",
    "\n",
    "##### Cuddy's top 10 verbs:\n",
    "go : 40,\n",
    "get : 25,\n",
    "make : 22,\n",
    "know : 19,\n",
    "could : 17,\n",
    "would : 16,\n",
    "want : 16,\n",
    "think : 14,\n",
    "find : 12,\n",
    "put : 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Wilson's Vocabularies in S1]\n",
    "\n",
    "##### Wilson's unique vocabularies:\n",
    "1205\n",
    "\n",
    "##### Wilson's top 10 nouns:\n",
    "get : 21,\n",
    "cancer : 19,\n",
    "yeah : 14,\n",
    "talk : 13,\n",
    "house : 13,\n",
    "something : 12,\n",
    "thing : 12,\n",
    "look : 11,\n",
    "time : 11,\n",
    "case : 10\n",
    "\n",
    "##### Wilson's top 10 adjectives:\n",
    "good : 17,\n",
    "wrong : 11,\n",
    "sure : 10,\n",
    "first : 9,\n",
    "right : 9,\n",
    "uh : 7,\n",
    "die : 6,\n",
    "great : 6,\n",
    "much : 6,\n",
    "old : 6\n",
    "\n",
    "\n",
    "##### Wilson's top 10 verbs:\n",
    "go : 51,\n",
    "get : 50,\n",
    "think : 27,\n",
    "want : 24,\n",
    "know : 21,\n",
    "say : 21,\n",
    "could : 20,\n",
    "would : 19,\n",
    "come : 16,\n",
    "need : 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Chase's Vocabularies in S1]\n",
    "\n",
    "##### Chase's unique vocabularies:\n",
    "1595\n",
    "\n",
    "##### Chase's top 10 nouns:\n",
    "test : 26,\n",
    "house : 23,\n",
    "blood : 22,\n",
    "get : 21,\n",
    "cause : 19,\n",
    "time : 15,\n",
    "something : 14,\n",
    "look : 14,\n",
    "anything : 13,\n",
    "poison : 12\n",
    "\n",
    "##### Chase's top 10 adjectives:\n",
    "right : 21,\n",
    "good : 19,\n",
    "wrong : 13,\n",
    "negative : 11,\n",
    "little : 11,\n",
    "last : 11,\n",
    "clear : 10,\n",
    "old : 10,\n",
    "clean : 9,\n",
    "give : 8\n",
    "\n",
    "\n",
    "##### Chase's top 10 verbs:\n",
    "go : 77,\n",
    "get : 75,\n",
    "know : 37,\n",
    "think : 36,\n",
    "could : 29,\n",
    "say : 29,\n",
    "would : 25,\n",
    "make : 24,\n",
    "want : 22,\n",
    "take : 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Cameron's Vocabularies in S1]\n",
    "\n",
    "##### Cameron's unique vocabularies:\n",
    "1575\n",
    "\n",
    "##### Cameron's top 10 nouns:\n",
    "house : 37,\n",
    "blood : 29,\n",
    "nothing : 19,\n",
    "get : 15,\n",
    "brain : 14,\n",
    "dr : 14,\n",
    "test : 14,\n",
    "heart : 13,\n",
    "cause : 12,\n",
    "history : 11\n",
    "\n",
    "##### Cameron's top 10 adjectives:\n",
    "right : 17,\n",
    "sure : 14,\n",
    "wrong : 12,\n",
    "new : 8,\n",
    "bad : 8,\n",
    "give : 7,\n",
    "negative : 7,\n",
    "good : 7,\n",
    "medical : 7,\n",
    "old : 7\n",
    "\n",
    "\n",
    "##### Cameron's top 10 verbs:\n",
    "go : 70,\n",
    "get : 67,\n",
    "know : 42,\n",
    "could : 35,\n",
    "think : 34,\n",
    "would : 26,\n",
    "want : 22,\n",
    "need : 21,\n",
    "make : 19,\n",
    "say : 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Foreman's Vocabularies in S1]\n",
    "\n",
    "##### Foreman's unique vocabularies:\n",
    "1930\n",
    "\n",
    "##### Foreman's top 10 nouns:\n",
    "blood : 33,\n",
    "brain : 30,\n",
    "house : 29,\n",
    "treatment : 25,\n",
    "test : 25,\n",
    "nothing : 22,\n",
    "guy : 20,\n",
    "cause : 20,\n",
    "heart : 19,\n",
    "work : 19\n",
    "\n",
    "##### Foreman's top 10 adjectives:\n",
    "right : 21,\n",
    "sure : 18,\n",
    "good : 17,\n",
    "little : 16,\n",
    "mean : 13,\n",
    "patient : 13,\n",
    "negative : 12,\n",
    "wrong : 12,\n",
    "better : 11,\n",
    "sick : 11\n",
    "\n",
    "\n",
    "##### Foreman's top 10 verbs:\n",
    "get : 101,\n",
    "go : 82,\n",
    "think : 48,\n",
    "could : 46,\n",
    "take : 43,\n",
    "know : 39,\n",
    "make : 35,\n",
    "would : 33,\n",
    "say : 26,\n",
    "want : 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import nltk\n",
    "import unidecode\n",
    "import glob\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag, map_tag\n",
    "import string\n",
    "from collections import Counter\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = 'D:/free time/house script'\n",
    "\n",
    "housescript = []\n",
    "cuddyscript = []\n",
    "wilsonscript = []\n",
    "chasescript = []\n",
    "cameronscript = []\n",
    "foremanscript = []\n",
    "for files in glob.glob(os.path.join(path, '*.txt')):\n",
    "    with open(files, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'House:' in line:\n",
    "                line = unidecode.unidecode(line.decode('utf8'))\n",
    "                line = re.sub(r'(House: )|\\n','',line)\n",
    "                housescript.append(line)\n",
    "            if 'Cuddy:' in line:\n",
    "                line = unidecode.unidecode(line.decode('utf8'))\n",
    "                line = re.sub(r'(Cuddy: )|\\n','',line)\n",
    "                cuddyscript.append(line)\n",
    "            if 'Wilson:' in line:\n",
    "                line = unidecode.unidecode(line.decode('utf8'))\n",
    "                line = re.sub(r'(Wilson: )|\\n','',line)\n",
    "                wilsonscript.append(line)    \n",
    "            if 'Chase:' in line:\n",
    "                line = unidecode.unidecode(line.decode('utf8'))\n",
    "                line = re.sub(r'(Chase: )|\\n','',line)\n",
    "                chasescript.append(line)\n",
    "            if 'Cameron:' in line:\n",
    "                line = unidecode.unidecode(line.decode('utf8'))\n",
    "                line = re.sub(r'(Cameron: )|\\n','',line)\n",
    "                cameronscript.append(line)\n",
    "            if 'Foreman:' in line:\n",
    "                line = unidecode.unidecode(line.decode('utf8'))\n",
    "                line = re.sub(r'(Foreman: )|\\n','',line)\n",
    "                foremanscript.append(line)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    #all to lowercase\n",
    "    text = text.lower()\n",
    "    #can't to can not (so the tokenize doesn't screw up can't -> ca, n't)\n",
    "    text = re.sub(r\"can't\",\"can not\",text)\n",
    "    #gonna -> going to, gotta -> got to\n",
    "    text = re.sub(r\"gonna\",\"going to\",text)\n",
    "    text = re.sub(r\"gotta\",\"got to\",text)\n",
    "    #remove the action e.g:[house's walking toward the patient's mom]\n",
    "    text = re.sub(r\"\\[.*?\\]\",\"\",text)\n",
    "    #tokenize (i can't do that. he's \"insane\"! -> 'i', 'ca', \"n't\", 'do', 'that', '.', 'he', \"'s\", '\"', 'insane', '\"','!') \n",
    "    tokens = TreebankWordTokenizer().tokenize(text)\n",
    "    #remove the 's/'re/n't/something like that. stopword is bound to be removed anyway\n",
    "    tokens = [re.sub(r\"n\\'.*|\\'.*\", '', s) for s in tokens]\n",
    "    #remove punctuation  \n",
    "    #punc = '\"#$%&\\'()*+,-/:;<=>@[\\\\]^_`{|}~' <- except .?!\n",
    "    tokens = [''.join(c for c in s if c not in string.punctuation) for s in tokens]\n",
    "    #remove remaining stopword\n",
    "    stop = set(stopwords.words('english'))\n",
    "    tokens = [s for s in tokens if s not in stop]\n",
    "    #lemmatize\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    tokens = [lmtzr.lemmatize(s, 'v') for s in tokens]\n",
    "    #remove the empty element after punctuation&stopword removal\n",
    "    tokens = [s for s in tokens if s]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "#get house's tokens\n",
    "housetokens = []\n",
    "for dialogue in housescript:\n",
    "    housetokens.extend(text_preprocessing(dialogue))\n",
    "\n",
    "#get cuddy's tokens\n",
    "cuddytokens = []\n",
    "for dialogue in cuddyscript:\n",
    "    cuddytokens.extend(text_preprocessing(dialogue))\n",
    "\n",
    "#get wilson's tokens\n",
    "wilsontokens = []\n",
    "for dialogue in wilsonscript:\n",
    "    wilsontokens.extend(text_preprocessing(dialogue))\n",
    "\n",
    "#get chase's tokens    \n",
    "chasetokens = []\n",
    "for dialogue in chasescript:\n",
    "    chasetokens.extend(text_preprocessing(dialogue))\n",
    "\n",
    "#get cameron's tokens    \n",
    "camerontokens = []\n",
    "for dialogue in cameronscript:\n",
    "    camerontokens.extend(text_preprocessing(dialogue))\n",
    "    \n",
    "#get foreman's tokens    \n",
    "foremantokens = []\n",
    "for dialogue in foremanscript:\n",
    "    foremantokens.extend(text_preprocessing(dialogue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tokens counter (into dict)\n",
    "house_tokens_counter = Counter(housetokens)\n",
    "cuddy_tokens_counter = Counter(cuddytokens)\n",
    "wilson_tokens_counter = Counter(wilsontokens)\n",
    "chase_tokens_counter = Counter(chasetokens)\n",
    "cameron_tokens_counter = Counter(camerontokens)\n",
    "foreman_tokens_counter = Counter(foremantokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House's unique vocabularies 4256\n",
      "Cuddy's unique vocabularies 1062\n",
      "Wilson's unique vocabularies 1205\n",
      "Chase's unique vocabularies 1595\n",
      "Cameron's unique vocabularies 1575\n",
      "Foreman's unique vocabularies 1930\n"
     ]
    }
   ],
   "source": [
    "#Character's unique vocabularies in season 1\n",
    "print \"House's unique vocabularies\", len(house_tokens_counter)\n",
    "print \"Cuddy's unique vocabularies\", len(cuddy_tokens_counter)\n",
    "print \"Wilson's unique vocabularies\", len(wilson_tokens_counter)\n",
    "print \"Chase's unique vocabularies\", len(chase_tokens_counter)\n",
    "print \"Cameron's unique vocabularies\", len(cameron_tokens_counter)\n",
    "print \"Foreman's unique vocabularies\", len(foreman_tokens_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many times House said lie/lies/lied (but there might be 'lie' as in laying down mixed in)\n",
    "house_tokens_counter['lie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOUSE_NOUNS\n",
      "get : 98\n",
      "time : 91\n",
      "guy : 81\n",
      "people : 74\n",
      "way : 70\n",
      "something : 69\n",
      "yeah : 66\n",
      "doctor : 65\n",
      "blood : 58\n",
      "thing : 55\n",
      "\n",
      "HOUSE_ADJ\n",
      "good : 98\n",
      "right : 83\n",
      "sure : 62\n",
      "wrong : 60\n",
      "new : 46\n",
      "bad : 46\n",
      "big : 44\n",
      "little : 44\n",
      "much : 40\n",
      "great : 38\n",
      "\n",
      "HOUSE_VERB\n",
      "get : 316\n",
      "go : 260\n",
      "know : 189\n",
      "think : 157\n",
      "would : 145\n",
      "say : 135\n",
      "want : 126\n",
      "make : 122\n",
      "could : 94\n",
      "take : 86\n"
     ]
    }
   ],
   "source": [
    "#pos tagging the tokens\n",
    "pos_tag_housetokens = pos_tag(housetokens)\n",
    "#simplify the pos_tag label\n",
    "simple_pos_tag_housetokens = [(word, map_tag('en-ptb', 'universal', tag)) for word, tag in pos_tag_housetokens]\n",
    "\n",
    "#prepare lists for noun, adj, verb separately\n",
    "noun = []\n",
    "adj = []\n",
    "verb = []\n",
    "\n",
    "#categorize nouns, adjs, and verbs into different lists\n",
    "for word, tag in simple_pos_tag_housetokens:\n",
    "    if tag==\"NOUN\":\n",
    "        noun.append(word)\n",
    "    elif tag==\"ADJ\":\n",
    "        adj.append(word)\n",
    "    elif tag==\"VERB\":\n",
    "        verb.append(word)\n",
    "\n",
    "#count the words in the list\n",
    "house_noun_count = Counter(noun)\n",
    "house_adj_count = Counter(adj)\n",
    "house_verb_count = Counter(verb)\n",
    "\n",
    "#print top 10 words (and its count) in nouns\n",
    "print \"HOUSE_NOUNS\"\n",
    "for key, value in sorted(house_noun_count.iteritems(), key=itemgetter(1), reverse=True)[:10]:\n",
    "    print(\"{} : {}\".format(key, value))\n",
    "    \n",
    "#print top 10 words (and its count) in adjectives\n",
    "print \"\\nHOUSE_ADJ\"\n",
    "for key, value in sorted(house_adj_count.iteritems(), key=itemgetter(1), reverse=True)[:10]:\n",
    "    print(\"{} : {}\".format(key, value))\n",
    "    \n",
    "#print top 10 words (and its count) in verbs\n",
    "print \"\\nHOUSE_VERB\"\n",
    "for key, value in sorted(house_verb_count.iteritems(), key=itemgetter(1), reverse=True)[:10]:\n",
    "    print(\"{} : {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDDY_NOUNS\n",
      "house : 22\n",
      "dr : 17\n",
      "doctor : 16\n",
      "people : 13\n",
      "hospital : 11\n",
      "guy : 10\n",
      "job : 10\n",
      "week : 10\n",
      "work : 9\n",
      "talk : 9\n",
      "\n",
      "CUDDY_ADJ\n",
      "good : 10\n",
      "right : 8\n",
      "clinic : 7\n",
      "patient : 7\n",
      "give : 7\n",
      "wrong : 7\n",
      "dr : 6\n",
      "sure : 5\n",
      "fine : 4\n",
      "great : 4\n",
      "\n",
      "CUDDY_VERB\n",
      "go : 40\n",
      "get : 25\n",
      "make : 22\n",
      "know : 19\n",
      "could : 17\n",
      "would : 16\n",
      "want : 16\n",
      "think : 14\n",
      "find : 12\n",
      "put : 11\n"
     ]
    }
   ],
   "source": [
    "#top 10 cuddy's nouns, adjs, verbs\n",
    "pos_tag_cuddytokens = pos_tag(cuddytokens)\n",
    "simple_pos_tag_cuddytokens = [(word, map_tag('en-ptb', 'universal', tag)) for word, tag in pos_tag_cuddytokens]\n",
    "\n",
    "noun = []\n",
    "adj = []\n",
    "verb = []\n",
    "\n",
    "for word, tag in simple_pos_tag_cuddytokens:\n",
    "    if tag==\"NOUN\":\n",
    "        noun.append(word)\n",
    "    elif tag==\"ADJ\":\n",
    "        adj.append(word)\n",
    "    elif tag==\"VERB\":\n",
    "        verb.append(word)\n",
    "        \n",
    "cuddy_noun_count = Counter(noun)\n",
    "cuddy_adj_count = Counter(adj)\n",
    "cuddy_verb_count = Counter(verb)\n",
    "\n",
    "print \"CUDDY_NOUNS\"\n",
    "for key, value in sorted(cuddy_noun_count.iteritems(), key=itemgetter(1), reverse=True)[:10]:\n",
    "    print(\"{} : {}\".format(key, value))\n",
    "\n",
    "print \"\\nCUDDY_ADJ\"\n",
    "for key, value in sorted(cuddy_adj_count.iteritems(), key=itemgetter(1), reverse=True)[:10]:\n",
    "    print(\"{} : {}\".format(key, value))\n",
    "    \n",
    "print \"\\nCUDDY_VERB\"\n",
    "for key, value in sorted(cuddy_verb_count.iteritems(), key=itemgetter(1), reverse=True)[:10]:\n",
    "    print(\"{} : {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WILSON_NOUNS\n",
      "get : 21\n",
      "cancer : 19\n",
      "yeah : 14\n",
      "talk : 13\n",
      "house : 13\n",
      "something : 12\n",
      "thing : 12\n",
      "look : 11\n",
      "time : 11\n",
      "case : 10\n",
      "\n",
      "WILSON_ADJ\n",
      "good : 17\n",
      "wrong : 11\n",
      "sure : 10\n",
      "first : 9\n",
      "right : 9\n",
      "uh : 7\n",
      "die : 6\n",
      "great : 6\n",
      "much : 6\n",
      "old : 6\n",
      "\n",
      "WILSON_VERB\n",
      "go : 51\n",
      "get : 50\n",
      "think : 27\n",
      "want : 24\n",
      "know : 21\n",
      "say : 21\n",
      "could : 20\n",
      "would : 19\n",
      "come : 16\n",
      "need : 14\n"
     ]
    }
   ],
   "source": [
    "#top 10 wilson's nouns, adjs, verbs\n",
    "pos_tag_wilsontokens = pos_tag(wilsontokens)\n",
    "simple_pos_tag_wilsontokens = [(word, map_tag('en-ptb', 'universal', tag)) for word, tag in pos_tag_wilsontokens]\n",
    "\n",
    "noun = []\n",
    "adj = []\n",
    "verb = []\n",
    "\n",
    "for word, tag in simple_pos_tag_wilsontokens:\n",
    "    if tag==\"NOUN\":\n",
    "        noun.append(word)\n",
    "    elif tag==\"ADJ\":\n",
    "        adj.append(word)\n",
    "    elif tag==\"VERB\":\n",
    "        verb.append(word)\n",
    "        \n",
    "wilson_noun_count = Counter(noun)\n",
    "wilson_adj_count = Counter(adj)\n",
    "wilson_verb_count = Counter(verb)\n",
    "\n",
    "print \"WILSON_NOUNS\"\n",
    "for key, value in sorted(wilson_noun_count.iteritems(), key=itemgetter(1), reverse=True)[:10]:\n",
    "    print(\"{} : {}\".format(key, value))\n",
    "\n",
    "print \"\\nWILSON_ADJ\"\n",
    "for key, value in sorted(wilson_adj_count.iteritems(), key=itemgetter(1), reverse=True)[:10]:\n",
    "    print(\"{} : {}\".format(key, value))\n",
    "    \n",
    "print \"\\nWILSON_VERB\"\n",
    "for key, value in sorted(wilson_verb_count.iteritems(), key=itemgetter(1), reverse=True)[:10]:\n",
    "    print(\"{} : {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHASE_NOUNS\n",
      "test : 26\n",
      "house : 23\n",
      "blood : 22\n",
      "get : 21\n",
      "cause : 19\n",
      "time : 15\n",
      "something : 14\n",
      "look : 14\n",
      "anything : 13\n",
      "poison : 12\n",
      "\n",
      "CHASE_ADJ\n",
      "right : 21\n",
      "good : 19\n",
      "wrong : 13\n",
      "negative : 11\n",
      "little : 11\n",
      "last : 11\n",
      "clear : 10\n",
      "old : 10\n",
      "clean : 9\n",
      "give : 8\n",
      "\n",
      "CHASE_VERB\n",
      "go : 77\n",
      "get : 75\n",
      "know : 37\n",
      "think : 36\n",
      "could : 29\n",
      "say : 29\n",
      "would : 25\n",
      "make : 24\n",
      "want : 22\n",
      "take : 22\n"
     ]
    }
   ],
   "source": [
    "#top 10 chase's nouns, adjs, verbs\n",
    "pos_tag_chasetokens = pos_tag(chasetokens)\n",
    "simple_pos_tag_chasetokens = [(word, map_tag('en-ptb', 'universal', tag)) for word, tag in pos_tag_chasetokens]\n",
    "\n",
    "noun = []\n",
    "adj = []\n",
    "verb = []\n",
    "\n",
    "for word, tag in simple_pos_tag_chasetokens:\n",
    "    if tag==\"NOUN\":\n",
    "        noun.append(word)\n",
    "    elif tag==\"ADJ\":\n",
    "        adj.append(word)\n",
    "    elif tag==\"VERB\":\n",
    "        verb.append(word)\n",
    "        \n",
    "chase_noun_count = Counter(noun)\n",
    "chase_adj_count = Counter(adj)\n",
    "chase_verb_count = Counter(verb)\n",
    "\n",
    "print \"CHASE_NOUNS\"\n",
    "for key, value in sorted(chase_noun_count.iteritems(), key=itemgetter(1), reverse=True)[:10]:\n",
    "    print(\"{} : {}\".format(key, value))\n",
    "\n",
    "print \"\\nCHASE_ADJ\"\n",
    "for key, value in sorted(chase_adj_count.iteritems(), key=itemgetter(1), reverse=True)[:10]:\n",
    "    print(\"{} : {}\".format(key, value))\n",
    "    \n",
    "print \"\\nCHASE_VERB\"\n",
    "for key, value in sorted(chase_verb_count.iteritems(), key=itemgetter(1), reverse=True)[:10]:\n",
    "    print(\"{} : {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMERON_NOUNS\n",
      "house : 37\n",
      "blood : 29\n",
      "nothing : 19\n",
      "get : 15\n",
      "brain : 14\n",
      "dr : 14\n",
      "test : 14\n",
      "heart : 13\n",
      "cause : 12\n",
      "history : 11\n",
      "\n",
      "CAMERON_ADJ\n",
      "right : 17\n",
      "sure : 14\n",
      "wrong : 12\n",
      "new : 8\n",
      "bad : 8\n",
      "give : 7\n",
      "negative : 7\n",
      "good : 7\n",
      "medical : 7\n",
      "old : 7\n",
      "\n",
      "CAMERON_VERB\n",
      "go : 70\n",
      "get : 67\n",
      "know : 42\n",
      "could : 35\n",
      "think : 34\n",
      "would : 26\n",
      "want : 22\n",
      "need : 21\n",
      "make : 19\n",
      "say : 18\n"
     ]
    }
   ],
   "source": [
    "#top 10 cameron's nouns, adjs, verbs\n",
    "pos_tag_camerontokens = pos_tag(camerontokens)\n",
    "simple_pos_tag_camerontokens = [(word, map_tag('en-ptb', 'universal', tag)) for word, tag in pos_tag_camerontokens]\n",
    "\n",
    "noun = []\n",
    "adj = []\n",
    "verb = []\n",
    "\n",
    "for word, tag in simple_pos_tag_camerontokens:\n",
    "    if tag==\"NOUN\":\n",
    "        noun.append(word)\n",
    "    elif tag==\"ADJ\":\n",
    "        adj.append(word)\n",
    "    elif tag==\"VERB\":\n",
    "        verb.append(word)\n",
    "        \n",
    "cameron_noun_count = Counter(noun)\n",
    "cameron_adj_count = Counter(adj)\n",
    "cameron_verb_count = Counter(verb)\n",
    "\n",
    "print \"CAMERON_NOUNS\"\n",
    "for key, value in sorted(cameron_noun_count.iteritems(), key=itemgetter(1), reverse=True)[:10]:\n",
    "    print(\"{} : {}\".format(key, value))\n",
    "\n",
    "print \"\\nCAMERON_ADJ\"\n",
    "for key, value in sorted(cameron_adj_count.iteritems(), key=itemgetter(1), reverse=True)[:10]:\n",
    "    print(\"{} : {}\".format(key, value))\n",
    "    \n",
    "print \"\\nCAMERON_VERB\"\n",
    "for key, value in sorted(cameron_verb_count.iteritems(), key=itemgetter(1), reverse=True)[:10]:\n",
    "    print(\"{} : {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOREMAN_NOUNS\n",
      "blood : 33\n",
      "brain : 30\n",
      "house : 29\n",
      "treatment : 25\n",
      "test : 25\n",
      "nothing : 22\n",
      "guy : 20\n",
      "cause : 20\n",
      "heart : 19\n",
      "work : 19\n",
      "\n",
      "FOREMAN_ADJ\n",
      "right : 21\n",
      "sure : 18\n",
      "good : 17\n",
      "little : 16\n",
      "mean : 13\n",
      "patient : 13\n",
      "negative : 12\n",
      "wrong : 12\n",
      "better : 11\n",
      "sick : 11\n",
      "\n",
      "FOREMAN_VERB\n",
      "get : 101\n",
      "go : 82\n",
      "think : 48\n",
      "could : 46\n",
      "take : 43\n",
      "know : 39\n",
      "make : 35\n",
      "would : 33\n",
      "say : 26\n",
      "want : 26\n"
     ]
    }
   ],
   "source": [
    "#top 10 foreman's nouns, adjs, verbs\n",
    "pos_tag_foremantokens = pos_tag(foremantokens)\n",
    "simple_pos_tag_foremantokens = [(word, map_tag('en-ptb', 'universal', tag)) for word, tag in pos_tag_foremantokens]\n",
    "\n",
    "noun = []\n",
    "adj = []\n",
    "verb = []\n",
    "\n",
    "for word, tag in simple_pos_tag_foremantokens:\n",
    "    if tag==\"NOUN\":\n",
    "        noun.append(word)\n",
    "    elif tag==\"ADJ\":\n",
    "        adj.append(word)\n",
    "    elif tag==\"VERB\":\n",
    "        verb.append(word)\n",
    "        \n",
    "foreman_noun_count = Counter(noun)\n",
    "foreman_adj_count = Counter(adj)\n",
    "foreman_verb_count = Counter(verb)\n",
    "\n",
    "print \"FOREMAN_NOUNS\"\n",
    "for key, value in sorted(foreman_noun_count.iteritems(), key=itemgetter(1), reverse=True)[:10]:\n",
    "    print(\"{} : {}\".format(key, value))\n",
    "\n",
    "print \"\\nFOREMAN_ADJ\"\n",
    "for key, value in sorted(foreman_adj_count.iteritems(), key=itemgetter(1), reverse=True)[:10]:\n",
    "    print(\"{} : {}\".format(key, value))\n",
    "    \n",
    "print \"\\nFOREMAN_VERB\"\n",
    "for key, value in sorted(foreman_verb_count.iteritems(), key=itemgetter(1), reverse=True)[:10]:\n",
    "    print(\"{} : {}\".format(key, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
